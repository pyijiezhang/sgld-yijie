{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "sns.set(font_scale=1.2, style='whitegrid')\n",
    "\n",
    "src_dir = (Path('..') / 'src').resolve()\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "data_dir = os.environ['DATADIR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ToyNoisyDataset(Dataset):\n",
    "    def __init__(self, n=10, obs_scale=1., aug_scale=1.):\n",
    "        super().__init__()\n",
    "\n",
    "        self._train = True\n",
    "        self._clean = True\n",
    "        self._aug = False\n",
    "        self.aug_scale = aug_scale\n",
    "\n",
    "        self.sigma = obs_scale\n",
    "\n",
    "        x = 1.5 * (2 * torch.rand(n, 1) - 1)\n",
    "        \n",
    "        self.targets = x + self.sigma * torch.randn_like(x)\n",
    "        self.clean_data = x\n",
    "        self.spur_data = torch.cat([x, torch.randn_like(x)], dim=-1)\n",
    "\n",
    "        x = torch.linspace(-6, 6, 100).unsqueeze(-1)\n",
    "\n",
    "        self.test_targets = x + self.sigma * torch.randn_like(x)\n",
    "        self.clean_test_data = x\n",
    "        self.spur_test_data = torch.cat([x, torch.randn_like(x)], dim=-1)\n",
    "\n",
    "    def train(self):\n",
    "        self._train = True\n",
    "        return self\n",
    "\n",
    "    def eval(self):\n",
    "        self._train = False\n",
    "        return self\n",
    "\n",
    "    def clean(self, mode=True):\n",
    "        self._clean = mode\n",
    "        return self\n",
    "\n",
    "    def aug(self, mode=True):\n",
    "        self._aug = mode\n",
    "        return self\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self._train:\n",
    "            return len(self.targets)\n",
    "        return len(self.test_targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self._train:\n",
    "            x = self.clean_data[index] if self._clean else self.spur_data[index]\n",
    "            if not self._clean and self._aug:\n",
    "                x[..., -1] += self.aug_scale * torch.randn_like(x[..., -1])\n",
    "            return x, self.targets[index]\n",
    "\n",
    "        x = self.clean_test_data if self._clean else self.spur_test_data[index]\n",
    "        return x, self.test_targets[index]\n",
    "\n",
    "dataset = ToyNoisyDataset(n=10, obs_scale=1.).train()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "x, y = dataset[:]\n",
    "ax.scatter(x.numpy(), y.numpy())\n",
    "ax.set(ylim=[-15,15], xlim=[-6,6])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Posterior predictive for Bayesian linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_pred(X, y, X_test, obs_scale=1., prior_scale=1.):\n",
    "    '''\n",
    "    X: n x d\n",
    "    y: n x 1\n",
    "    '''\n",
    "    d = X.size(-1)\n",
    "    \n",
    "    post_prec = (X.T @ X).div(obs_scale**2) + torch.eye(d).div(prior_scale**2)\n",
    "    post_mean = torch.linalg.solve(post_prec, X.T @ y).div(obs_scale**2)\n",
    "\n",
    "    test_mean = X_test @ post_mean\n",
    "    # Just get diagonal of covariance.\n",
    "    test_var = (X_test * torch.linalg.solve(post_prec, X_test.T).T).sum(dim=-1, keepdim=True) \\\n",
    "                + obs_scale**2\n",
    "\n",
    "    return test_mean, test_var, post_mean, post_prec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.distributions import Normal\n",
    "\n",
    "from data_aug.optim import SGLD\n",
    "from data_aug.optim.lr_scheduler import CosineLR\n",
    "\n",
    "class GaussianPriorAugmentedRegressionLoss(nn.Module):\n",
    "  '''Gaussian likelihood + prior.\n",
    "\n",
    "  To get the unbiased density estimate, multiply by N.\n",
    "  '''\n",
    "  def __init__(self, params, aug_scale=10, obs_scale=1, prior_scale=1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.theta = params\n",
    "    self.omega = aug_scale\n",
    "    self.sigma = prior_scale\n",
    "    self.sigma_obs = obs_scale\n",
    "\n",
    "  def forward(self, obs_mean, Y, N=1):\n",
    "    p_obs = Normal(obs_mean, self.sigma_obs)\n",
    "    energy = -p_obs.log_prob(Y).mean()\n",
    "    \n",
    "    for p in self.theta:\n",
    "      prior = Normal(torch.zeros_like(p), self.sigma)\n",
    "      energy -= prior.log_prob(p).sum().div(N)\n",
    "    \n",
    "    return energy\n",
    "\n",
    "\n",
    "def run_sgld(net, epochs, train_loader, criterion, sgld, sgld_scheduler=None):\n",
    "  samples = []\n",
    "\n",
    "  for _ in tqdm(range(epochs)):\n",
    "    net.train()\n",
    "    for (X, Y) in train_loader:\n",
    "      sgld.zero_grad()\n",
    "\n",
    "      f_hat = net(X)\n",
    "      loss = criterion(f_hat, Y, N=N)\n",
    "\n",
    "      loss.backward()\n",
    "\n",
    "      if sgld_scheduler is None:\n",
    "        sgld.step()\n",
    "        samples.append(deepcopy(net.state_dict()))\n",
    "      else:\n",
    "        if sgld_scheduler.get_last_beta() < sgld_scheduler.beta:\n",
    "          sgld.step(noise=False)\n",
    "        else:\n",
    "          sgld.step()\n",
    "\n",
    "          if sgld_scheduler.should_sample():\n",
    "            samples.append(deepcopy(net.state_dict()))\n",
    "\n",
    "        sgld_scheduler.step()\n",
    "  \n",
    "  if sgld_scheduler is None:\n",
    "    samples = samples[1000::100]\n",
    "  return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "\n",
    "_X, _y = dataset.train().clean()[:]\n",
    "_X_test, _ = dataset.eval().clean()[:]\n",
    "\n",
    "exact_mean, exact_var, post_mean, post_prec = post_pred(\n",
    "    torch.cat([_X, torch.ones(len(_X), 1)], dim=-1), _y,\n",
    "    torch.cat([_X_test, torch.ones(len(_X_test), 1)], dim=-1),\n",
    "    obs_scale=dataset.sigma)\n",
    "\n",
    "print(post_mean)\n",
    "print(torch.linalg.pinv(post_prec))\n",
    "\n",
    "ax.scatter(_X[:, 0].numpy(), _y[:, 0].numpy(), alpha=.2, c='black')\n",
    "ax.plot(_X_test[:, 0].numpy(), exact_mean[:, 0].numpy(), label='Exact', c='green')\n",
    "ax.plot(_X_test[:, 0].numpy(), (exact_mean - 2 * exact_var.sqrt())[:, 0].numpy(),\n",
    "             linestyle='dashed', c='green')\n",
    "ax.plot(_X_test[:, 0].numpy(), (exact_mean + 2 * exact_var.sqrt())[:, 0].numpy(),\n",
    "             linestyle='dashed', c='green')\n",
    "# ax.fill_between(_X_test[:, 0].numpy(), y1=(exact_mean - 2 * exact_var.sqrt())[:, 0].numpy(),\n",
    "#                      y2=(exact_mean + 2 * exact_var.sqrt())[:, 0].numpy(), alpha=.2, color='green')\n",
    "\n",
    "######################\n",
    "\n",
    "dataset = dataset.train().clean()\n",
    "\n",
    "N = len(dataset)\n",
    "epochs = 50000\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "net = nn.Linear(_X.size(-1), 1)\n",
    "criterion = GaussianPriorAugmentedRegressionLoss(net.parameters(), prior_scale=1,\n",
    "                                                 obs_scale=dataset.sigma)\n",
    "\n",
    "sgld = SGLD(net.parameters(), lr=1e-3, momentum=0, temperature=1 / N)\n",
    "sgld_scheduler = None #CosineLR(sgld, n_cycles=1, n_samples=100, T_max=len(train_loader) * epochs)\n",
    "\n",
    "samples = run_sgld(net, epochs, train_loader, criterion, sgld, sgld_scheduler)\n",
    "\n",
    "_y_test = []\n",
    "with torch.no_grad():\n",
    "  for s in samples:\n",
    "    net.load_state_dict(s)\n",
    "    _y_test.append(net(_X_test))\n",
    "  _y_test = torch.stack(_y_test)\n",
    "\n",
    "  samples = torch.Tensor([[s['weight'].item() for s in samples],\n",
    "                         [s['bias'].item() for s in samples]]).T\n",
    "\n",
    "pred_mean = _y_test.mean(dim=0)\n",
    "pred_var = dataset.sigma**2 + _y_test.pow(2).mean(dim=0) \\\n",
    "           - pred_mean.pow(2)\n",
    "\n",
    "print(samples.mean(dim=0, keepdim=True))\n",
    "print(samples.T.cov())\n",
    "\n",
    "ax.plot(_X_test[:, 0].numpy(), pred_mean[:, 0].numpy(), label='SGLD', c='red')\n",
    "ax.plot(_X_test[:, 0].numpy(), (pred_mean - 2 * pred_var.sqrt())[:, 0].numpy(),\n",
    "             linestyle='dotted', c='red')\n",
    "ax.plot(_X_test[:, 0].numpy(), (pred_mean + 2 * pred_var.sqrt())[:, 0].numpy(),\n",
    "             linestyle='dotted', c='red')\n",
    "ax.set(title='Clean Data')\n",
    "ax.legend()\n",
    "\n",
    "fig.show()\n",
    "# fig.savefig('clean_data.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Spurious Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "\n",
    "_X, _y = dataset.train().clean(False)[:]\n",
    "_X_test, _ = dataset.eval().clean(False)[:]\n",
    "\n",
    "ax.scatter(_X[:, 0].numpy(), _y[:, 0].numpy(), alpha=.2, c='black')\n",
    "\n",
    "exact_mean, exact_var, post_mean, post_prec = post_pred(\n",
    "    torch.cat([_X, torch.ones(len(_X), 1)], dim=-1), _y,\n",
    "    torch.cat([_X_test, torch.ones(len(_X_test), 1)], dim=-1),\n",
    "    obs_scale=dataset.sigma)\n",
    "\n",
    "print(post_mean)\n",
    "print(torch.linalg.pinv(post_prec))\n",
    "\n",
    "ax.plot(_X_test[:, 0].numpy(), exact_mean[:, 0].numpy(), label='Exact', c='green')\n",
    "ax.plot(_X_test[:, 0].numpy(), (exact_mean - 2 * exact_var.sqrt())[:, 0].numpy(),\n",
    "             linestyle='dashed', c='green')\n",
    "ax.plot(_X_test[:, 0].numpy(), (exact_mean + 2 * exact_var.sqrt())[:, 0].numpy(),\n",
    "             linestyle='dashed', c='green')\n",
    "\n",
    "#########\n",
    "\n",
    "dataset = dataset.train().clean(False)\n",
    "\n",
    "N = len(dataset)\n",
    "epochs = 50000\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "net = nn.Linear(_X.size(-1), 1)\n",
    "criterion = GaussianPriorAugmentedRegressionLoss(net.parameters(), prior_scale=1,\n",
    "                                                 obs_scale=dataset.sigma)\n",
    "\n",
    "sgld = SGLD(net.parameters(), lr=3e-5, momentum=0, temperature=1 / N)\n",
    "sgld_scheduler = None #CosineLR(sgld, n_cycles=1, n_samples=100, T_max=len(train_loader) * epochs)\n",
    "\n",
    "samples = run_sgld(net, epochs, train_loader, criterion, sgld, sgld_scheduler)\n",
    "\n",
    "_y_test = []\n",
    "with torch.no_grad():\n",
    "  for s in samples:\n",
    "    net.load_state_dict(s)\n",
    "    _y_test.append(net(_X_test))\n",
    "  _y_test = torch.stack(_y_test)\n",
    "\n",
    "  samples = torch.cat([\n",
    "    torch.cat([s['weight'] for s in samples], dim=0),\n",
    "    torch.cat([s['bias'] for s in samples], dim=0).unsqueeze(-1)], dim=-1)\n",
    "\n",
    "pred_mean = _y_test.mean(dim=0)\n",
    "pred_var = dataset.sigma**2 + _y_test.pow(2).mean(dim=0) \\\n",
    "           - pred_mean.pow(2)\n",
    "\n",
    "print(samples.mean(dim=0, keepdim=True))\n",
    "print(samples.T.cov())\n",
    "\n",
    "ax.plot(_X_test[:, 0].numpy(), pred_mean[:, 0].numpy(), label='SGLD', c='red')\n",
    "ax.plot(_X_test[:, 0].numpy(), (pred_mean - 2 * pred_var.sqrt())[:, 0].numpy(),\n",
    "             linestyle='dotted', c='red')\n",
    "ax.plot(_X_test[:, 0].numpy(), (pred_mean + 2 * pred_var.sqrt())[:, 0].numpy(),\n",
    "             linestyle='dotted', c='red')\n",
    "\n",
    "ax.set(title='Spurious Data')\n",
    "ax.legend()\n",
    "\n",
    "fig.show()\n",
    "# fig.savefig('spur_data.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Spurious Data + Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "\n",
    "n_aug = 5\n",
    "_X, _y = [], []\n",
    "for _ in range(n_aug):\n",
    "    _A, _b = dataset.train().clean(False).aug()[:]\n",
    "    _X.append(_A)\n",
    "    _y.append(_b)\n",
    "_X, _y = torch.cat(_X, dim=0), torch.cat(_y, dim=0)\n",
    "ax.scatter(_X[:len(dataset), 0].numpy(), _y[:len(dataset), 0].numpy(), alpha=.2, c='black')\n",
    "\n",
    "_X_test, _ = dataset.eval().clean(False).aug()[:]\n",
    "\n",
    "exact_mean, exact_var, post_mean, post_prec = post_pred(\n",
    "    torch.cat([_X, torch.ones(len(_X), 1)], dim=-1), _y,\n",
    "    torch.cat([_X_test, torch.ones(len(_X_test), 1)], dim=-1),\n",
    "    obs_scale=dataset.sigma)\n",
    "print(post_mean)\n",
    "print(torch.linalg.pinv(post_prec))\n",
    "\n",
    "ax.plot(_X_test[:, 0].numpy(), exact_mean[:, 0].numpy(), label='Exact', c='green')\n",
    "ax.plot(_X_test[:, 0].numpy(), (exact_mean - 2 * exact_var.sqrt())[:, 0].numpy(),\n",
    "             linestyle='dashed', c='green')\n",
    "ax.plot(_X_test[:, 0].numpy(), (exact_mean + 2 * exact_var.sqrt())[:, 0].numpy(),\n",
    "             linestyle='dashed', c='green')\n",
    "\n",
    "######################\n",
    "\n",
    "dataset.train().clean(False).aug()\n",
    "\n",
    "N = len(dataset)\n",
    "epochs = 50000\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "net = nn.Linear(_X.size(-1), 1)\n",
    "criterion = GaussianPriorAugmentedRegressionLoss(net.parameters(), prior_scale=1,\n",
    "                                                 obs_scale=dataset.sigma * np.sqrt(epochs))\n",
    "sgld = SGLD(net.parameters(), lr=3e-5, momentum=0, temperature=1 / N)\n",
    "sgld_scheduler = None #CosineLR(sgld, n_cycles=1, n_samples=100, T_max=len(train_loader) * epochs)\n",
    "\n",
    "samples = run_sgld(net, epochs, train_loader, criterion, sgld, sgld_scheduler)\n",
    "\n",
    "_y_test = []\n",
    "with torch.no_grad():\n",
    "  for s in samples:\n",
    "    net.load_state_dict(s)\n",
    "    _y_test.append(net(_X_test))\n",
    "  _y_test = torch.stack(_y_test)\n",
    "\n",
    "  samples = torch.cat([\n",
    "    torch.cat([s['weight'] for s in samples], dim=0),\n",
    "    torch.cat([s['bias'] for s in samples], dim=0).unsqueeze(-1)], dim=-1)\n",
    "\n",
    "pred_mean = _y_test.mean(dim=0)\n",
    "pred_var = dataset.sigma**2 + _y_test.pow(2).mean(dim=0) \\\n",
    "           - pred_mean.pow(2)\n",
    "\n",
    "print(samples.mean(dim=0, keepdim=True))\n",
    "print(samples.T.cov())\n",
    "\n",
    "ax.plot(_X_test[:, 0].numpy(), pred_mean[:, 0].numpy(), label='SGLD', c='red')\n",
    "ax.plot(_X_test[:, 0].numpy(), (pred_mean - 2 * pred_var.sqrt())[:, 0].numpy(),\n",
    "             linestyle='dotted', c='red')\n",
    "ax.plot(_X_test[:, 0].numpy(), (pred_mean + 2 * pred_var.sqrt())[:, 0].numpy(),\n",
    "             linestyle='dotted', c='red')\n",
    "\n",
    "ax.set(title='Spurious Data + Augmentation')\n",
    "ax.legend()\n",
    "\n",
    "fig.show()\n",
    "# fig.savefig('spur_data_aug.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef16d1c2b9bdea86a9f19387e5c6274ab469aa69d27340e178608868525b66dc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('data-aug-likelihood': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
